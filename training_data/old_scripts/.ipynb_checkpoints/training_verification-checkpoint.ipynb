{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c56651-6113-49a7-8342-8f2613252cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import time \n",
    "import numpy as np\n",
    "import json\n",
    "import tpch_training as tp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b588599c-a1c6-47df-99a4-c0e784ffaba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "['./training_results/sf10_main_test_ind.json', './training_results/sf10_main_test_ind1.json', './training_results/sf10_main_test_ind2.json']\n"
     ]
    }
   ],
   "source": [
    "DET_PARAMS_FNAME = \"./training_params/detparams_5.json\"\n",
    "DET_PARAMS = None\n",
    "with open(DET_PARAMS_FNAME, 'rb') as f:\n",
    "    DET_PARAMS = json.load(f)\n",
    "    print(len(DET_PARAMS))\n",
    "\n",
    "training_fnames = ['./training_results/'+x for x in os.listdir('./training_results') if 'json' in x and 'sf10_main_test_ind' in x]\n",
    "len(training_fnames)\n",
    "print(training_fnames)\n",
    "\n",
    "def get_spark_params(result_dict):\n",
    "    param_vals = []\n",
    "    for param in tp.SPARK_PARAMETERS:\n",
    "        for p in result_dict['params']:\n",
    "            if p['name'] == param['name']:\n",
    "                param_vals.append(p['cur_value'])\n",
    "    return tuple(param_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e25b516-4e8b-400d-acc3-d212e28798df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " '1g',\n",
       " 2,\n",
       " 1,\n",
       " '1g',\n",
       " '48m',\n",
       " 'true',\n",
       " 'true',\n",
       " '32k',\n",
       " '4m',\n",
       " 'true',\n",
       " 0.6,\n",
       " '128',\n",
       " 'false',\n",
       " 'lz4',\n",
       " 1,\n",
       " 200,\n",
       " 200,\n",
       " 0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults = tuple(a['default_value'] for a in tp.SPARK_PARAMETERS)\n",
    "defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbd0d60-624b-498c-8598-d51cc9fad737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "{'./training_results/sf10_main_test_ind.json': 108, './training_results/sf10_main_test_ind1.json': 71, './training_results/sf10_main_test_ind2.json': 124}\n",
      "{'./training_results/sf10_main_test_ind.json': 91, './training_results/sf10_main_test_ind1.json': 71, './training_results/sf10_main_test_ind2.json': 91}\n"
     ]
    }
   ],
   "source": [
    "fname_numdata = {}\n",
    "fname_numdet = {}\n",
    "deterministic_data = {}\n",
    "\n",
    "for fname in training_fnames:\n",
    "    with open(fname,'r') as file:\n",
    "        try:\n",
    "            file_data = json.load(file)\n",
    "        except:\n",
    "            continue\n",
    "        fname_numdata[fname] = len(file_data)\n",
    "        deterministic_data[fname] = {}\n",
    "        \n",
    "        for k in DET_PARAMS:\n",
    "            if k in file_data:\n",
    "                deterministic_data[fname][k] = file_data[k]\n",
    "        fname_numdet[fname] = len(deterministic_data[fname])\n",
    "print(sum(fname_numdata.values()))\n",
    "print(fname_numdata)\n",
    "print(fname_numdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42544271-132c-4399-985a-f7dd53979d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_results/sf10_main_test_ind.json \n",
      " 17.73514676094055 15.959094762802124 21.55800437927246 15.73914647102356\n",
      "./training_results/sf10_main_test_ind1.json \n",
      " 16.60610342025757 20.517776012420654 22.39563512802124 16.37746787071228\n",
      "./training_results/sf10_main_test_ind2.json \n",
      " 19.527423620224 20.204445362091064 22.412273168563843 17.694279670715332\n"
     ]
    }
   ],
   "source": [
    "det_params = {}\n",
    "det_rt = {}\n",
    "for fname, data in deterministic_data.items():\n",
    "    det_params[fname] = []\n",
    "    det_rt[fname] = []\n",
    "    for result_dict in data.values():\n",
    "        det_params[fname].append(get_spark_params(result_dict))\n",
    "        if result_dict['runtimes']:\n",
    "            det_rt[fname].append(result_dict['runtimes']['total'])\n",
    "prev_fname = fname\n",
    "for fname in det_params:\n",
    "    assert det_params[fname][0] == defaults, f'{det_params[fname][0]} !=\\n{defaults}'\n",
    "    #assert str(det_params[fname]) == str(det_params[prev_fname]), fname + \" \" + prev_fname\n",
    "    print(fname, '\\n',det_rt[fname][0], det_rt[fname][-1], max(det_rt[fname]), min(det_rt[fname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b409616-6e21-4589-82b9-e9e170a5b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many different param combos have we tried?\n",
    "fname_num_params = {}\n",
    "fname_valid = {}\n",
    "for fname in training_fnames:\n",
    "    with open(fname,'r+') as file:\n",
    "        try:\n",
    "            file_data = json.load(file)\n",
    "        except:\n",
    "            continue\n",
    "        fname_num_params[fname] = set()\n",
    "        fname_valid[fname] = 0\n",
    "        for result_dict in file_data.values():\n",
    "            fname_num_params[fname].add(get_spark_params(result_dict))\n",
    "            fname_valid[fname] += 1 if result_dict['runtimes'] else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47e55f03-f255-4833-84c9-c0f3f0ffd27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "/sf10_main_test_ind.json \n",
      "num unique params 112 total runs 108 valid runs 113\n",
      "/sf10_main_test_ind1.json \n",
      "num unique params 75 total runs 71 valid runs 77\n",
      "/sf10_main_test_ind2.json \n",
      "num unique params 134 total runs 124 valid runs 135\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(x) for x in fname_num_params.values()]))\n",
    "for fname, vals in fname_num_params.items():\n",
    "    print(fname[18:60], '\\nnum unique params', len(vals), 'total runs',fname_numdata[fname] , 'valid runs', fname_valid[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40919c75-26c1-4eb3-9939-47d8f37a0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#det_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546477e5-b61e-4d51-959c-9415f624929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall runs avg  17.91431 median 17.60726 range  5.81886 std  1.48662\n",
      "overall runs avg  18.58805 median 18.05703 range  6.01817 std  1.54407\n",
      "overall runs avg  19.32314 median 19.2727 range  4.71799 std  0.84013\n"
     ]
    }
   ],
   "source": [
    "for fname in det_rt:\n",
    "    all_runs = []\n",
    "    for run in det_rt[fname]:\n",
    "        all_runs.append(run)\n",
    "        #print('avg ', round(np.average(run), 5), 'median', round(np.median(run), 5), 'range ', round(max(run)-min(run),5), 'std ', round(np.std(run), 5))\n",
    "    print('overall runs avg ', round(np.average(all_runs), 5), 'median', round(np.median(all_runs), 5), 'range ', round(max(all_runs)-min(all_runs),5), 'std ', round(np.std(all_runs), 5))\n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a26a7b1f-36cd-43c1-be87-05c10fb12385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./training_results/sf10_main_test_ind.json', './training_results/sf10_main_test_ind1.json', './training_results/sf10_main_test_ind2.json']\n",
      "./training_results/sf10_main_test_ind.json 139\n",
      "dict_keys(['default', 'spark.executor.cores', 'spark.executor.memory', 'spark.executor.instances', 'spark.driver.cores', 'spark.driver.memory', 'spark.reducer.maxSizeInFlight', 'spark.shuffle.compress', 'spark.shuffle.spill.compress', 'spark.shuffle.file.buffer', 'spark.broadcast.blockSize', 'spark.broadcast.compress', 'spark.memory.fraction', 'spark.rpc.message.maxSize', 'spark.rdd.compress', 'spark.io.compression.codec', 'spark.sql.shuffle.partitions', 'spark.default.parallelism', 'spark.memory.storageFraction'])\n",
      "default, min: 0, max: 3, median 1.5, avg: 1.5  default: (0, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29275/2537650153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0manalyze_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29275/2537650153.py\u001b[0m in \u001b[0;36manalyze_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mmin_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmax_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmin_runtime\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_runtime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "#training_fnames = ['./training_results/'+x for x in os.listdir('./training_results') if 'json' in x and 'test_clear_ports' in x]\n",
    "#direc = '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results'\n",
    "#training_fnames = [f'{direc}/{x}'for x in os.listdir(direc) if 'json' in x and 'nobackup_deterministic_raw_runtimes' in x]\n",
    "direc = './training_results'\n",
    "training_fnames = [f'{direc}/{x}'for x in os.listdir(direc) if 'json' in x and 'sf10_main_test_ind' in x]\n",
    "\n",
    "len(training_fnames)\n",
    "print(training_fnames)\n",
    "for FNAME in  training_fnames:\n",
    "    import json\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    with open(FNAME,'r+') as file:\n",
    "        try:\n",
    "            file_data = json.load(file)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    class Parameter:\n",
    "        def __init__(self, name):\n",
    "            self.name = name\n",
    "            self.val_to_results = {}\n",
    "\n",
    "        def add(self, param_val, results):\n",
    "            self.val_to_results[param_val] = results\n",
    "\n",
    "        def get_total(self, param_val):\n",
    "            if param_val in self.val_to_results:\n",
    "                return self.val_to_results[param_val][\"total\"]\n",
    "\n",
    "        def get_param_vals(self):\n",
    "            return set(self.val_to_results.keys())\n",
    "\n",
    "    param_name_to_param_obj = {}\n",
    "\n",
    "    def populate_params():\n",
    "        #analyze one file\n",
    "\n",
    "        f = open(FNAME)\n",
    "        data = json.load(f)\n",
    "        print(FNAME, len(data))\n",
    "        for k in data:\n",
    "            d = data[k]\n",
    "            params = [p for p in d[\"params\"] if p['spark_param']]\n",
    "            runtimes = d[\"runtimes\"]\n",
    "            if len(runtimes) == 0:\n",
    "                continue\n",
    "\n",
    "            all_default = True\n",
    "            for p in params:\n",
    "                if str(p['cur_value']) != str(p['default_value']):\n",
    "                    varying_param = p['name']\n",
    "                    all_default = False\n",
    "                    break\n",
    "            if all_default:\n",
    "                if 'default' not in param_name_to_param_obj:\n",
    "                    param_name_to_param_obj[\"default\"] = Parameter('default')\n",
    "                    \n",
    "                obj = param_name_to_param_obj[\"default\"]\n",
    "                obj.add(len(obj.val_to_results), runtimes)\n",
    "                if k in runtimes and type(runtimes[k]) == list:\n",
    "                    print(runtimes[k])\n",
    "                    print('last', sorted([(runtimes[k][-1], k) for k in runtimes], reverse=True))\n",
    "                    qt = [(runtimes[k][0], k) for k in runtimes if k != 'total']\n",
    "                    print(min(qt), max(qt), sum([x[0] for x in qt]))\n",
    "                    print('first', sorted(qt, reverse=True))\n",
    "                    # TODO REMOVE\n",
    "                    param_name_to_param_obj[\"default\"] = {'total': runtimes['total'][10:]} \n",
    "                    # remove first runtime which is always much longer for some reason???\n",
    "                continue\n",
    "\n",
    "            if varying_param not in param_name_to_param_obj:\n",
    "                param_name_to_param_obj[varying_param] = Parameter(varying_param)\n",
    "            obj = param_name_to_param_obj[varying_param]\n",
    "            assert \"total\" in runtimes\n",
    "            obj.add(p['cur_value'], runtimes)\n",
    "            \n",
    "        print(param_name_to_param_obj.keys())\n",
    "\n",
    "    def analyze_results():\n",
    "        populate_params()\n",
    "        default = param_name_to_param_obj[\"default\"]\n",
    "        default_total = default.get_param_vals()\n",
    "        mins = []\n",
    "        names = []\n",
    "        diffs = []\n",
    "        stds = []\n",
    "        for p in param_name_to_param_obj:\n",
    "            min_runtime = float(\"inf\")\n",
    "            max_runtime = -float(\"inf\")\n",
    "            times = []\n",
    "            if p != 'default':\n",
    "                obj = param_name_to_param_obj[p]\n",
    "                for k in obj.get_param_vals():\n",
    "                    total_time = obj.get_total(k)\n",
    "                    if type(total_time) == list:\n",
    "                        times.extend(total_time)\n",
    "                        min_runtime = min(min_runtime, min(total_time))\n",
    "                        max_runtime = max(max_runtime, max(total_time))\n",
    "                    else:\n",
    "                        times.append(total_time)\n",
    "                        min_runtime = min(min_runtime, total_time)\n",
    "                        max_runtime = max(max_runtime, total_time)\n",
    "                if min_runtime == max_runtime:\n",
    "                    max_runtime += .001\n",
    "\n",
    "\n",
    "            else:\n",
    "                times.extend(default_total)\n",
    "                min_runtime = min(default_total)\n",
    "                max_runtime = max(default_total)\n",
    "            stds.append(np.std(times))\n",
    "            if p == 'default':\n",
    "                print(f\"{p}, min: {round(min_runtime,5)}, max: {round(max_runtime,5)}, median {round(np.median(times),5)}, avg: {round(np.average(times),5)}  default: {round(min(default_total),5), round(max(default_total),5)}\")\n",
    "            mins.append(min_runtime)\n",
    "            diffs.append(max_runtime - min_runtime)\n",
    "            names.append(p)\n",
    "\n",
    "        #save total time std to csv\n",
    "        df = pd.DataFrame(list(zip(names, stds)),\n",
    "        columns =['name', 'standard_dev_total_times'])\n",
    "        df.to_csv(\"./training_sensitivity/all_runtime_stds.csv\", mode='w')\n",
    "\n",
    "        #plot std\n",
    "        fig = plt.figure(figsize = (10, 5))\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.bar(names, stds, bottom=[0]*len(names), width=0.2)\n",
    "        plt.title(\"Standard deviation of total query times for each parameter\")\n",
    "        plt.xlabel(\"Parameter\")\n",
    "        plt.ylabel(\"Standard deviation of times\")\n",
    "\n",
    "        plt.savefig(f\"./training_sensitivity/all_runtime_stds{FNAME[-7:-5]}.jpg\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "        #plot min/max times for each parameter\n",
    "        fig = plt.figure(figsize = (10, 5))\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.bar(names, diffs, bottom=mins, width=0.2)\n",
    "        plt.title(\"Range of total query times for each parameter\")\n",
    "        plt.xlabel(\"Parameter\")\n",
    "        plt.ylabel(\"Range of times\")\n",
    "        plt.savefig(f\"./training_sensitivity/all_runtime_ranges{FNAME[-7:-5]}.jpg\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    analyze_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a9c3f-e628-4fc1-a01d-40648ca2e1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d760218e-a112-466a-948c-102e346072f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_39.json', '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_40.json', '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_43.json', '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_42.json', '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_41.json']\n",
      "error loading ../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_41.json\n",
      "12504\n",
      "error loading ../../../../nobackup1/hoped/spark-autotuner/training_data/training_results/sf324_main_nobackup_deterministic_and_random_41.json\n",
      "12230\n",
      "all:\n",
      " \n",
      "num unique params 5978 total runs 6252 valid runs 5884\n",
      "ministic_and_random_39.json \n",
      "num unique params 64 total runs 64 valid runs 63\n",
      "ministic_and_random_40.json \n",
      "num unique params 2118 total runs 2118 valid runs 2005\n",
      "ministic_and_random_43.json \n",
      "num unique params 2237 total runs 2237 valid runs 2092\n",
      "ministic_and_random_42.json \n",
      "num unique params 1833 total runs 1833 valid runs 1724\n"
     ]
    }
   ],
   "source": [
    "direc = '../../../../nobackup1/hoped/spark-autotuner/training_data/training_results'\n",
    "training_fnames = [f'{direc}/{x}'for x in os.listdir(direc) if 'json' in x and 'and_random' in x]\n",
    "len(training_fnames)\n",
    "print(training_fnames)\n",
    "fname_numdata = {'all':0}\n",
    "\n",
    "for fname in training_fnames:\n",
    "    with open(fname,'r+') as file:\n",
    "        \n",
    "        try:\n",
    "            file_data = json.load(file)\n",
    "            fname_numdata[fname] = len(file_data)\n",
    "            fname_numdata['all'] += len(file_data)\n",
    "        except:\n",
    "            print(\"error loading\", fname)\n",
    "print(sum(fname_numdata.values()))\n",
    "\n",
    "# how many different param combos have we tried?\n",
    "fname_num_params = {'all':set()}\n",
    "fname_valid = {'all':0}\n",
    "for fname in training_fnames:\n",
    "    with open(fname,'r+') as file:\n",
    "        try:\n",
    "            file_data = json.load(file)\n",
    "        except:\n",
    "            print(\"error loading\", fname)\n",
    "            continue\n",
    "        fname_num_params[fname] = set()\n",
    "        fname_valid[fname] = 0\n",
    "        for result_dict in file_data.values():\n",
    "            fname_num_params[fname].add(get_spark_params(result_dict))\n",
    "            fname_valid[fname] += 1 if result_dict['runtimes'] else 0\n",
    "            fname_num_params['all'].add(get_spark_params(result_dict))\n",
    "            fname_valid['all'] += 1 if result_dict['runtimes'] else 0\n",
    "print(sum([len(x) for x in fname_num_params.values()]))\n",
    "for fname, vals in fname_num_params.items():\n",
    "    if fname == 'all':\n",
    "        print(\"all:\")\n",
    "\n",
    "    print(fname[100:160], '\\nnum unique params', len(vals), 'total runs',fname_numdata[fname] , 'valid runs', fname_valid[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8b527-a285-4ccb-b0ac-56d175ed3505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
