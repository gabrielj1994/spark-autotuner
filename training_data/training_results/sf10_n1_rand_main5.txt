{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6684 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 6, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '88m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '96k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '18m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '192', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 60, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.929208993911743, 'load_tables': 10.229219198226929, 'q1': 38.528984785079956, 'q2': 13.112998008728027, 'q3': 57.93384885787964, 'q4': 44.98417019844055, 'q5': 64.88457465171814, 'q6': 16.829474687576294, 'q7': 61.51006603240967, 'q8': 26.080934524536133, 'q9': 40.452659606933594, 'q10': 35.61674737930298, 'q11': 5.158776760101318, 'q12': 21.70825743675232, 'q13': 40.869277477264404, 'q14': 15.008862733840942, 'q15': 46.0403356552124, 'q16': 8.392128705978394, 'q17': 51.58241367340088, 'q18': 83.88028573989868, 'q19': 12.928298711776733, 'q20': 22.345964908599854, 'q21': 135.23780250549316, 'q22': 13.24672245979309, 'total': 856.3335855007172, 'overall': 873.4920136928558}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6683 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 7, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '14m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '160', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 100, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6683 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 7, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '96m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '4m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '192', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 120, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.21732759475708, 'load_tables': 9.807016611099243, 'q1': 35.985095262527466, 'q2': 11.747472524642944, 'q3': 50.15732526779175, 'q4': 40.918142557144165, 'q5': 58.08397364616394, 'q6': 15.72136402130127, 'q7': 63.17672610282898, 'q8': 21.678723335266113, 'q9': 45.210110902786255, 'q10': 36.46405029296875, 'q11': 5.75664210319519, 'q12': 22.29543447494507, 'q13': 34.86234402656555, 'q14': 15.494852781295776, 'q15': 37.31937599182129, 'q16': 10.648108005523682, 'q17': 51.62152147293091, 'q18': 78.0977087020874, 'q19': 12.327703714370728, 'q20': 22.704936981201172, 'q21': 133.21616888046265, 'q22': 12.625197649002075, 'total': 816.1129786968231, 'overall': 832.1373229026794}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6682 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 8, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '96m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '24m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '192', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6681 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 6, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '64m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '24m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 60, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 260, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 7.066008567810059, 'load_tables': 10.783143997192383, 'q1': 33.03636026382446, 'q2': 13.328572511672974, 'q3': 48.11091375350952, 'q4': 40.461456298828125, 'q5': 53.81033205986023, 'q6': 14.896239995956421, 'q7': 63.15432929992676, 'q8': 20.679880142211914, 'q9': 40.32072830200195, 'q10': 32.2559494972229, 'q11': 4.801495552062988, 'q12': 21.67341661453247, 'q13': 36.57420825958252, 'q14': 14.148019552230835, 'q15': 35.74500226974487, 'q16': 8.257092714309692, 'q17': 49.341660499572754, 'q18': 76.85682678222656, 'q19': 11.153897523880005, 'q20': 21.918415069580078, 'q21': 140.8404517173767, 'q22': 13.180701971054077, 'total': 794.5459506511688, 'overall': 812.3951032161713}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6680 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 2, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '56m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '12m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 100, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6680 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '8g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '24m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 120, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 140, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.73911714553833, 'load_tables': 9.762006759643555, 'q1': 31.818199157714844, 'q2': 13.498774766921997, 'q3': 51.1998074054718, 'q4': 41.69280791282654, 'q5': 58.11816453933716, 'q6': 13.24218201637268, 'q7': 61.999396562576294, 'q8': 20.204975128173828, 'q9': 46.424670457839966, 'q10': 32.98322772979736, 'q11': 5.855227947235107, 'q12': 22.75209403038025, 'q13': 36.502705335617065, 'q14': 18.088553428649902, 'q15': 35.46169710159302, 'q16': 11.747434616088867, 'q17': 52.824535846710205, 'q18': 80.25905084609985, 'q19': 11.042405843734741, 'q20': 21.117475271224976, 'q21': 137.44072771072388, 'q22': 13.068654775619507, 'total': 817.3427684307098, 'overall': 833.8438923358917}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '8g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 4, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '80k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '12m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 100, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 8, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '5g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '56m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '18m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '160', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 140, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '56m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '112k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '18m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '160', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 100, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 60, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '5g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 8, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '96k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '14m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 70, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 60, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 8, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '48m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '4m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 180, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 8, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '96k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '8m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 50, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '64m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '96k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '12m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 70, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 140, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6679 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '6g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '22m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 340, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.945433855056763, 'load_tables': 10.222249269485474, 'q1': 35.290629863739014, 'q2': 13.493122100830078, 'q3': 49.76210045814514, 'q4': 41.918652296066284, 'q5': 59.11718726158142, 'q6': 15.786959409713745, 'q7': 64.6922173500061, 'q8': 21.006812810897827, 'q9': 45.80132579803467, 'q10': 36.96549654006958, 'q11': 5.901123523712158, 'q12': 23.62047028541565, 'q13': 37.01132369041443, 'q14': 15.958974838256836, 'q15': 37.2122848033905, 'q16': 8.531556606292725, 'q17': 53.479087114334106, 'q18': 81.42355537414551, 'q19': 12.024293422698975, 'q20': 22.309649229049683, 'q21': 148.30624175071716, 'q22': 13.794630289077759, 'total': 843.4076948165894, 'overall': 860.5753779411316}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6677 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 5, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '8g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '56m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '18m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 100, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 7.81217885017395, 'load_tables': 10.263693571090698, 'q1': 30.280778169631958, 'q2': 14.174875020980835, 'q3': 47.5988552570343, 'q4': 40.16266679763794, 'q5': 55.30745506286621, 'q6': 13.721192836761475, 'q7': 64.27065968513489, 'q8': 20.268816471099854, 'q9': 42.89637064933777, 'q10': 35.468116760253906, 'q11': 4.818632125854492, 'q12': 21.0374436378479, 'q13': 37.50802707672119, 'q14': 16.390851259231567, 'q15': 35.06463694572449, 'q16': 10.994510889053345, 'q17': 53.61793613433838, 'q18': 79.70995354652405, 'q19': 10.657231092453003, 'q20': 19.98062014579773, 'q21': 128.94544386863708, 'q22': 13.286431550979614, 'total': 796.161504983902, 'overall': 814.2373774051666}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6675 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '8g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 2, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '88m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '48k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '8m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 90, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6675 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '80k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '6m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 140, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.992422342300415, 'load_tables': 10.128969192504883, 'q1': 33.67129325866699, 'q2': 12.52477216720581, 'q3': 47.19578957557678, 'q4': 42.577972173690796, 'q5': 55.354079246520996, 'q6': 15.540977954864502, 'q7': 69.64269757270813, 'q8': 21.685529232025146, 'q9': 49.062705278396606, 'q10': 36.762486696243286, 'q11': 5.060168981552124, 'q12': 21.89933705329895, 'q13': 37.97277235984802, 'q14': 14.73422622680664, 'q15': 36.454527854919434, 'q16': 8.112818717956543, 'q17': 54.08452749252319, 'q18': 80.6060676574707, 'q19': 11.816962718963623, 'q20': 20.902016401290894, 'q21': 144.59029245376587, 'q22': 14.040761709213257, 'total': 834.2927827835083, 'overall': 851.4141743183136}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6673 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '6g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '64k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '24m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6673 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '7g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 2, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '88m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '64k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '12m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 220, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.256710767745972, 'load_tables': 9.332551717758179, 'q1': 33.32263493537903, 'q2': 13.317498922348022, 'q3': 49.695738554000854, 'q4': 40.36313486099243, 'q5': 57.033318758010864, 'q6': 13.898358821868896, 'q7': 64.58175539970398, 'q8': 20.402624368667603, 'q9': 44.013625383377075, 'q10': 34.15807509422302, 'q11': 5.7788004875183105, 'q12': 22.25233554840088, 'q13': 38.59955191612244, 'q14': 17.197312593460083, 'q15': 35.636796951293945, 'q16': 12.106804609298706, 'q17': 54.64419221878052, 'q18': 77.49827122688293, 'q19': 11.253231525421143, 'q20': 21.11645531654358, 'q21': 127.31230401992798, 'q22': 12.697222709655762, 'total': 806.880044221878, 'overall': 822.4693067073822}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6667 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '5g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '88m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '64k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '10m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 60, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 340, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6667 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '5g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 8, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '112k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '20m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 20, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.332702875137329, 'load_tables': 9.715414762496948, 'q1': 28.025121450424194, 'q2': 12.362717866897583, 'q3': 43.15746855735779, 'q4': 38.3798463344574, 'q5': 52.93925189971924, 'q6': 12.45180058479309, 'q7': 57.532076835632324, 'q8': 19.672016620635986, 'q9': 41.59234285354614, 'q10': 28.974980115890503, 'q11': 3.7219014167785645, 'q12': 18.975998640060425, 'q13': 34.10483121871948, 'q14': 13.773746252059937, 'q15': 31.60951805114746, 'q16': 9.480914831161499, 'q17': 44.563153982162476, 'q18': 74.81435179710388, 'q19': 9.283987283706665, 'q20': 18.70669388771057, 'q21': 144.21374011039734, 'q22': 12.419187784194946, 'total': 750.7556483745575, 'overall': 766.8037660121918}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6668 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '56m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '112k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '10m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 70, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 340, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.3, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6668 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 4, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '48m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '96k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '8m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 100, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6668 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 2, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '128k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '6m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 80, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 100, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 7.382571697235107, 'load_tables': 9.886528491973877, 'q1': 30.70255732536316, 'q2': 13.52884817123413, 'q3': 44.16131234169006, 'q4': 40.16614842414856, 'q5': 56.425217390060425, 'q6': 13.158562421798706, 'q7': 59.77084922790527, 'q8': 18.890034198760986, 'q9': 42.84309697151184, 'q10': 32.523969650268555, 'q11': 5.336418628692627, 'q12': 20.636424779891968, 'q13': 35.34248685836792, 'q14': 15.441846132278442, 'q15': 33.97202706336975, 'q16': 10.208912372589111, 'q17': 49.49492835998535, 'q18': 78.9449028968811, 'q19': 9.866506576538086, 'q20': 19.638418197631836, 'q21': 131.49180507659912, 'q22': 13.218711614608765, 'total': 775.7639846801758, 'overall': 793.0330848693848}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6662 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '7g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 4, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '88m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '8m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'snappy', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 50, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6662 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 6, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '80m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '80k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '12m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.SparkContext$.checkResourcesPerTask$1(SparkContext.scala:2905)\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2926)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:563)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6662 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '4g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '96m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '18m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 110, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 140, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 6.667290449142456, 'load_tables': 10.063496828079224, 'q1': 31.896931409835815, 'q2': 12.39737057685852, 'q3': 48.38902950286865, 'q4': 42.706459045410156, 'q5': 55.705320835113525, 'q6': 14.996534585952759, 'q7': 64.24462175369263, 'q8': 22.5999653339386, 'q9': 45.893669843673706, 'q10': 35.8654682636261, 'q11': 5.324990510940552, 'q12': 20.739107847213745, 'q13': 35.76364231109619, 'q14': 13.608750820159912, 'q15': 34.89638543128967, 'q16': 9.1276376247406, 'q17': 52.023446798324585, 'q18': 78.61867642402649, 'q19': 11.223101139068604, 'q20': 20.362955808639526, 'q21': 141.35581922531128, 'q22': 13.497183799743652, 'total': 811.2370688915253, 'overall': 827.967856168747}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6657 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 7, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '96m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '64k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '4m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.8, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '192', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 130, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 140, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 7.358433246612549, 'load_tables': 9.918332576751709, 'q1': 30.621503829956055, 'q2': 13.506625890731812, 'q3': 48.71617126464844, 'q4': 40.99262022972107, 'q5': 57.05325365066528, 'q6': 14.031893014907837, 'q7': 66.26983189582825, 'q8': 20.315176248550415, 'q9': 46.642024517059326, 'q10': 36.449798345565796, 'q11': 5.2569358348846436, 'q12': 21.098668575286865, 'q13': 36.24790596961975, 'q14': 13.398879766464233, 'q15': 35.98735499382019, 'q16': 9.05808973312378, 'q17': 50.46044588088989, 'q18': 76.98506712913513, 'q19': 10.642334461212158, 'q20': 20.579095363616943, 'q21': 132.7604742050171, 'q22': 13.05083966255188, 'total': 800.1249904632568, 'overall': 817.4017562866211}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6656 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 3, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '64m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '80k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '22m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '224', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 110, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 260, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6656 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 8, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '6g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 7, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '48m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '112k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '10m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '192', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 50, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 380, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.4, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {'build_config': 7.3259172439575195, 'load_tables': 9.912159204483032, 'q1': 34.92606067657471, 'q2': 12.232255458831787, 'q3': 49.01668357849121, 'q4': 40.66864895820618, 'q5': 54.96718382835388, 'q6': 16.312251806259155, 'q7': 61.876672983169556, 'q8': 20.13936996459961, 'q9': 43.7704541683197, 'q10': 31.588520050048828, 'q11': 6.294907569885254, 'q12': 21.01246190071106, 'q13': 36.30353808403015, 'q14': 15.374353170394897, 'q15': 36.53028440475464, 'q16': 8.118026494979858, 'q17': 51.359952211380005, 'q18': 77.46079468727112, 'q19': 11.937463283538818, 'q20': 21.521369695663452, 'q21': 137.13557267189026, 'q22': 12.591164827346802, 'total': 801.1379904747009, 'overall': 818.3760669231415}}
{'params': [{'name': 'sf', 'spark_param': False, 'cur_value': 10, 'default_value': 1, 'possible_values': [1, 10, 100, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'main5', 'default_value': 'main5', 'possible_values': ['rand', 'det']}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Linux', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '3.10.0-1062.el7.x86_64', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '#1 SMP Wed Aug 7 18:08:02 UTC 2019', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 20, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'node362', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.1.3.62', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '40:f2:e9:bb:60:f0', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'x86_64', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '62 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '36864 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '6653 GB', 'default_value': None, 'possible_values': []}, {'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '3g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 5, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 3, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '2g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '72m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '128k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '16m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '256', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 2, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 90, 'default_value': 100, 'possible_values': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 300, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.7, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: The number of cores per executor (=1) has to be >= the number of cpus per task = 2.\n\tat org.apache.spark.resource.ResourceUtils$.validateTaskCpusLargeEnough(ResourceUtils.scala:403)\n\tat org.apache.spark.resource.ResourceProfile.calculateTasksAndLimitingResource(ResourceProfile.scala:169)\n\tat org.apache.spark.resource.ResourceProfile.$anonfun$limitingResource$1(ResourceProfile.scala:139)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.resource.ResourceProfile.limitingResource(ResourceProfile.scala:138)\n\tat org.apache.spark.resource.ResourceProfileManager.addResourceProfile(ResourceProfileManager.scala:95)\n\tat org.apache.spark.resource.ResourceProfileManager.<init>(ResourceProfileManager.scala:49)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:455)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n'}
