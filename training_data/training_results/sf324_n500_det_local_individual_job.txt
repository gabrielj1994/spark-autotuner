{'params': [{'name': 'spark.executor.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.executor.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g', '5g', '6g', '7g', '8g']}, {'name': 'spark.executor.instances', 'spark_param': True, 'cur_value': 2, 'default_value': 2, 'possible_values': [2, 3, 4, 5, 6, 7, 8]}, {'name': 'spark.driver.cores', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2, 3, 4]}, {'name': 'spark.driver.memory', 'spark_param': True, 'cur_value': '1g', 'default_value': '1g', 'possible_values': ['1g', '2g', '3g', '4g']}, {'name': 'spark.reducer.maxSizeInFlight', 'spark_param': True, 'cur_value': '48m', 'default_value': '48m', 'possible_values': ['48m', '56m', '64m', '72m', '80m', '88m', '96m']}, {'name': 'spark.shuffle.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.spill.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.shuffle.file.buffer', 'spark_param': True, 'cur_value': '32k', 'default_value': '32k', 'possible_values': ['32k', '48k', '64k', '80k', '96k', '112k', '128k']}, {'name': 'spark.broadcast.blockSize', 'spark_param': True, 'cur_value': '4m', 'default_value': '4m', 'possible_values': ['4m', '6m', '8m', '10m', '12m', '14m', '16m', '18m', '20m', '22m', '24m']}, {'name': 'spark.broadcast.compress', 'spark_param': True, 'cur_value': 'true', 'default_value': 'true', 'possible_values': ['true', 'false']}, {'name': 'spark.memory.fraction', 'spark_param': True, 'cur_value': 0.6, 'default_value': 0.6, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'spark.rpc.message.maxSize', 'spark_param': True, 'cur_value': '128', 'default_value': '128', 'possible_values': ['128', '160', '192', '224', '256']}, {'name': 'spark.rdd.compress', 'spark_param': True, 'cur_value': 'false', 'default_value': 'false', 'possible_values': ['true', 'false']}, {'name': 'spark.io.compression.codec', 'spark_param': True, 'cur_value': 'lz4', 'default_value': 'lz4', 'possible_values': ['lz4', 'snappy']}, {'name': 'spark.task.cpus', 'spark_param': True, 'cur_value': 1, 'default_value': 1, 'possible_values': [1, 2]}, {'name': 'spark.sql.shuffle.partitions', 'spark_param': True, 'cur_value': 200, 'default_value': 200, 'possible_values': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}, {'name': 'spark.default.parallelism', 'spark_param': True, 'cur_value': 200, 'default_value': 200, 'possible_values': [20, 60, 100, 140, 180, 220, 260, 300, 340, 380]}, {'name': 'spark.memory.storageFraction', 'spark_param': True, 'cur_value': 0.5, 'default_value': 0.5, 'possible_values': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}, {'name': 'sf', 'spark_param': False, 'cur_value': 324, 'default_value': 1, 'possible_values': [1, 10, 60, 300]}, {'name': 'job_name', 'spark_param': False, 'cur_value': 'local_individual_job', 'default_value': 1, 'possible_values': [1, 10, 60]}, {'name': 'platform', 'spark_param': False, 'cur_value': 'Windows', 'default_value': None, 'possible_values': []}, {'name': 'platform-release', 'spark_param': False, 'cur_value': '10', 'default_value': None, 'possible_values': []}, {'name': 'platform-version', 'spark_param': False, 'cur_value': '10.0.22621', 'default_value': None, 'possible_values': []}, {'name': 'architecture', 'spark_param': False, 'cur_value': 'AMD64', 'default_value': None, 'possible_values': []}, {'name': 'num_cpus', 'spark_param': False, 'cur_value': 12, 'default_value': None, 'possible_values': []}, {'name': 'hostname', 'spark_param': False, 'cur_value': 'hopes_laptop', 'default_value': None, 'possible_values': []}, {'name': 'ip-address', 'spark_param': False, 'cur_value': '10.31.57.4', 'default_value': None, 'possible_values': []}, {'name': 'mac-address', 'spark_param': False, 'cur_value': '97:94:d1:46:8a:77', 'default_value': None, 'possible_values': []}, {'name': 'processor', 'spark_param': False, 'cur_value': 'Intel64 Family 6 Model 154 Stepping 4, GenuineIntel', 'default_value': None, 'possible_values': []}, {'name': 'ram', 'spark_param': False, 'cur_value': '16 GB', 'default_value': None, 'possible_values': []}, {'name': 'total_storage', 'spark_param': False, 'cur_value': '935 GB', 'default_value': None, 'possible_values': []}, {'name': 'free_storage', 'spark_param': False, 'cur_value': '235 GB', 'default_value': None, 'possible_values': []}], 'runtimes': {}, 'msg': 'An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Invalid Spark URL: spark://HeartbeatReceiver@hopes_laptop.mit.edu:63825\r\n\tat org.apache.spark.rpc.RpcEndpointAddress$.apply(RpcEndpointAddress.scala:66)\r\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:140)\r\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\r\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\r\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\r\n\tat org.apache.spark.executor.Executor.<init>(Executor.scala:244)\r\n\tat org.apache.spark.scheduler.local.LocalEndpoint.<init>(LocalSchedulerBackend.scala:64)\r\n\tat org.apache.spark.scheduler.local.LocalSchedulerBackend.start(LocalSchedulerBackend.scala:132)\r\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:222)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:585)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n'}
